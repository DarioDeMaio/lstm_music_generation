{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nLfbNbrOtL14"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Matplotlib is building the font cache; this may take a moment.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas\n",
        "import music21\n",
        "from music21 import *\n",
        "import os\n",
        "import IPython\n",
        "from PIL import Image\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import copy\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8L2FyX_teXY",
        "outputId": "b3dd3ae6-1116-407c-b5c7-1dc516dc91f3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/music21/midi/translate.py:863: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=5, channel=None, data=b'Copyright \\xa9 2006 by Bernd Kr\\xfcger'>; getting generic Instrument\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/music21/midi/translate.py:863: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=5, channel=None, data=b'Copyright \\xa9 1997 by Bernd Kr\\xfcger'>; getting generic Instrument\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/music21/midi/translate.py:863: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=5, channel=None, data=b'Copyright \\xa9 2005 by Bernd Kr\\xfcger'>; getting generic Instrument\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/music21/midi/translate.py:863: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=5, channel=None, data=b'Copyright \\xa9 2006 by Bernd Krueger'>; getting generic Instrument\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 21 MIDI files.\n"
          ]
        }
      ],
      "source": [
        "path = 'dataset/mozart'\n",
        "all_midis = []\n",
        "\n",
        "for i in os.listdir(path):\n",
        "    if i.endswith('.mid'):\n",
        "        tr = os.path.join(path, i)\n",
        "        try:\n",
        "            midi = music21.converter.parse(tr)\n",
        "            all_midis.append(midi)\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading {tr}: {e}\")\n",
        "\n",
        "print(f\"Loaded {len(all_midis)} MIDI files.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "acwQHxs8ttlx",
        "outputId": "256d6fa2-e0a2-4089-cc09-568e712bd830"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "55802\n"
          ]
        }
      ],
      "source": [
        "def extract_notes(file):\n",
        "    notes = []\n",
        "    pick = None\n",
        "    for f in file:\n",
        "        song = instrument.partitionByInstrument(f)\n",
        "        for part in song.parts:\n",
        "            pick = part.recurse()\n",
        "            for element in pick:\n",
        "                if isinstance(element, note.Note):\n",
        "                    notes.append(str(element.pitch))\n",
        "                elif isinstance(element, chord.Chord):\n",
        "                    notes.append('.'.join(str(n) for n in element.normalOrder))\n",
        "    return notes\n",
        "notes = extract_notes(all_midis)\n",
        "print(len(notes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "oWgNxFy9tw5T"
      },
      "outputs": [],
      "source": [
        "def show(music):\n",
        "    music.write('midi', 'img/output.mid')\n",
        "\n",
        "def chords_n_notes(notes):\n",
        "    melody = []\n",
        "    offset = 0\n",
        "    for n in notes:\n",
        "        if ('.' in n) or n.isdigit():\n",
        "            chord_notes = n.split('.')\n",
        "            note_objs = [note.Note(int(j)) for j in chord_notes]\n",
        "            chord_snip = chord.Chord(note_objs)\n",
        "            chord_snip.offset = offset\n",
        "            melody.append(chord_snip)\n",
        "        else:\n",
        "            note_snip = note.Note(n)\n",
        "            note_snip.offset = offset\n",
        "            melody.append(note_snip)\n",
        "        offset += 1\n",
        "\n",
        "    melody_midi = stream.Stream(melody)\n",
        "    return melody_midi\n",
        "\n",
        "# melody_midi = chords_n_notes(notes)\n",
        "# show(melody_midi)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bx_xoWm7txd-",
        "outputId": "b9ba96a8-525e-4d1a-f1ce-2135318c39db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total unique notes in the Corpus: 229\n",
            "Average recurrenc for a note in Corpus: 243.6768558951965\n",
            "Most frequent note in Corpus appeared: 2355 times\n",
            "Least frequent note in Corpus appeared: 1 time\n"
          ]
        }
      ],
      "source": [
        "count_num = Counter(notes)\n",
        "print(\"Total unique notes in the Corpus:\", len(count_num))\n",
        "keys = list(count_num.keys())\n",
        "values = list(count_num.values())\n",
        "\n",
        "def Average(lst):\n",
        "    return sum(lst) / len(lst)\n",
        "print(\"Average recurrenc for a note in Corpus:\", Average(values))\n",
        "print(\"Most frequent note in Corpus appeared:\", max(values), \"times\")\n",
        "print(\"Least frequent note in Corpus appeared:\", min(values), \"time\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1znt3r8t0OW",
        "outputId": "2824612c-ff45-490a-9e90-ca31b4a42c8a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total number of notes that occur less than 100 times: 145\n"
          ]
        }
      ],
      "source": [
        "#Getting a list of rare chords\n",
        "rare_note = []\n",
        "for index, (key, value) in enumerate(count_num.items()):\n",
        "    if value < 100:\n",
        "        m =  key\n",
        "        rare_note.append(m)\n",
        "\n",
        "print(\"Total number of notes that occur less than 100 times:\", len(rare_note))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7K7MjYZt2aG",
        "outputId": "c04e14f5-483b-4dff-9ad3-9601786ad714"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total number of characters: 55802\n",
            "Number of unique characters: 229\n"
          ]
        }
      ],
      "source": [
        "symb = sorted(list(set(notes)))\n",
        "\n",
        "L_corpus = len(notes)\n",
        "L_symb = len(symb)\n",
        "\n",
        "mapping = dict((c, i) for i, c in enumerate(symb))\n",
        "reverse_mapping = dict((i, c) for i, c in enumerate(symb))\n",
        "\n",
        "print(\"Total number of characters:\", L_corpus)\n",
        "print(\"Number of unique characters:\", L_symb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmy4Vi4Lt3--",
        "outputId": "3c9ec21c-e514-4ee2-8cdd-f92f73ddba7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total number of sequences in the Corpus: 55752\n"
          ]
        }
      ],
      "source": [
        "length = 50\n",
        "features = []\n",
        "targets = []\n",
        "for i in range(0, L_corpus - length, 1):\n",
        "    feature = notes[i:i + length]\n",
        "    target = notes[i + length]\n",
        "    features.append([mapping[j] for j in feature])\n",
        "    targets.append(mapping[target])\n",
        "\n",
        "\n",
        "L_datapoints = len(targets)\n",
        "print(\"Total number of sequences in the Corpus:\", L_datapoints)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "PGCGWtJTt5e-"
      },
      "outputs": [],
      "source": [
        "X = (np.reshape(features, (L_datapoints, length, 1)))/ float(L_symb)\n",
        "y = torch.nn.functional.one_hot(torch.tensor(targets))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "6kVKyx0rt62e"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nftBGdsNt7zH",
        "outputId": "52bc2201-aa88-4280-8670-3ad45bd4342e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_7138/2548854802.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  y_train_tensor = torch.tensor(y_train)\n",
            "/tmp/ipykernel_7138/2548854802.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  y_val_tensor = torch.tensor(y_val)\n",
            "/tmp/ipykernel_7138/2548854802.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  y_test_tensor = torch.tensor(y_test)\n"
          ]
        }
      ],
      "source": [
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train)\n",
        "y_train_tensor = torch.argmax(y_train_tensor, dim=1)\n",
        "\n",
        "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
        "y_val_tensor = torch.tensor(y_val)\n",
        "y_val_tensor = torch.argmax(y_val_tensor, dim=1)\n",
        "\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test)\n",
        "y_test_tensor = torch.argmax(y_test_tensor, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Yx1B8KTvt9PO"
      },
      "outputs": [],
      "source": [
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size_1=512, hidden_size_2=256, dropout_rate=0.2, output_size=None):\n",
        "        super(LSTMModel, self).__init__()\n",
        "\n",
        "        self.lstm1 = nn.LSTM(input_size, hidden_size_1, num_layers=3, batch_first=True, bidirectional=True)\n",
        "        self.norm1 = nn.LayerNorm(hidden_size_1 * 2)\n",
        "\n",
        "        self.lstm2 = nn.LSTM(hidden_size_1 * 2, hidden_size_2, num_layers=3, batch_first=True, bidirectional=True)\n",
        "        self.norm2 = nn.LayerNorm(hidden_size_2 * 2)\n",
        "\n",
        "        self.lstm3 = nn.LSTM(hidden_size_2 * 2, hidden_size_2, num_layers=3, batch_first=True, bidirectional=True)\n",
        "        self.norm3 = nn.LayerNorm(hidden_size_2*2)\n",
        "\n",
        "        self.bn1 = nn.BatchNorm1d(hidden_size_2*2)\n",
        "        self.fc1 = nn.Linear(hidden_size_2 * 2, hidden_size_2)\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(hidden_size_2, hidden_size_2),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.Linear(hidden_size_2, hidden_size_2),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.Linear(hidden_size_2, hidden_size_2),\n",
        "        )\n",
        "        self.dropout1 = nn.Dropout(dropout_rate)\n",
        "        self.dropout2 = nn.Dropout(dropout_rate)\n",
        "\n",
        "        # self.fc2 = nn.Linear(hidden_size_2, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x, _ = self.lstm1(x)\n",
        "        x = self.norm1(x)\n",
        "\n",
        "        x, _ = self.lstm2(x)\n",
        "        x = self.norm2(x)\n",
        "\n",
        "        x, _ = self.lstm3(x)\n",
        "        x = self.norm3(x)\n",
        "\n",
        "        x = x[:, -1, :]\n",
        "        x = self.bn1(x)\n",
        "        x = F.gelu(self.fc1(x))\n",
        "        x = self.dropout2(x)\n",
        "\n",
        "        x = self.mlp(x)\n",
        "\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ywPyUINct-1t",
        "outputId": "5af9253b-367b-4b0f-a9e1-39e1a41490cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[13], line 34\u001b[0m\n\u001b[1;32m     32\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model(batch_X)\n\u001b[1;32m     33\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(y_pred, batch_y)\n\u001b[0;32m---> 34\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     36\u001b[0m epoch_train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
            "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/_tensor.py:626\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    618\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    619\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    624\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    625\u001b[0m     )\n\u001b[0;32m--> 626\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/autograd/graph.py:823\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    826\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    827\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = LSTMModel(input_size=X_train.shape[2], output_size=y.shape[1]).to(device)\n",
        "optimizer = torch.optim.Adamax(model.parameters(), lr=0.0001)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "batch_size = 256\n",
        "train_dataset = torch.utils.data.TensorDataset(X_train_tensor, y_train_tensor)\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "val_dataset = torch.utils.data.TensorDataset(X_val_tensor, y_val_tensor)\n",
        "val_loader = torch.utils.data.DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "\n",
        "epochs = 200\n",
        "best_val_loss = float('inf')\n",
        "patience = 5\n",
        "trigger_times = 0\n",
        "\n",
        "train_loss_history = []\n",
        "val_loss_history = []\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    print(f\"Epoch {epoch}/{epochs}\")\n",
        "    model.train()\n",
        "    epoch_train_loss = 0\n",
        "    epoch_val_loss = 0\n",
        "    for batch_X, batch_y in train_loader:\n",
        "        batch_X = batch_X.to(device)\n",
        "        batch_y = batch_y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        y_pred = model(batch_X)\n",
        "        loss = criterion(y_pred, batch_y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_train_loss += loss.item()\n",
        "\n",
        "    epoch_train_loss /= len(train_loader)\n",
        "    train_loss_history.append(epoch_train_loss)\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      for batch_X, batch_y in val_loader:\n",
        "        batch_X = batch_X.to(device)\n",
        "        batch_y = batch_y.to(device)\n",
        "        val_pred = model(batch_X)\n",
        "        val_loss = criterion(val_pred, batch_y)\n",
        "        epoch_val_loss += val_loss.item()\n",
        "\n",
        "      val_loss_history.append(epoch_val_loss / len(val_loader))\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        plt.figure(figsize=(10, 5))\n",
        "        plt.plot(train_loss_history, label='Train Loss')\n",
        "        plt.plot(val_loss_history, label='Validation Loss')\n",
        "        plt.title(f'Epoch {epoch} - Training and Validation Loss')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.show()\n",
        "        plt.clf()\n",
        "        plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8fi6TYaZuKSL"
      },
      "outputs": [],
      "source": [
        "def melody_generator(note_count, model, X_test, reverse_mapping, L_symb, temperature=1.0):\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        music = []\n",
        "        notes_generated = []\n",
        "\n",
        "        for _ in range(note_count):\n",
        "            seed = X_test[np.random.randint(0, len(X_test) - 1)]\n",
        "            seed_tensor = torch.tensor(seed, dtype=torch.float32).unsqueeze(0).to(device)\n",
        "            prediction = model(seed_tensor)\n",
        "            prediction = prediction.squeeze(0)\n",
        "\n",
        "            prediction = torch.log_softmax(prediction / temperature, dim=-1)\n",
        "            prediction_probs = torch.exp(prediction)\n",
        "            index = torch.argmax(prediction_probs).item()\n",
        "\n",
        "            index_N = index / float(L_symb)\n",
        "            notes_generated.append(index)\n",
        "            music.append(reverse_mapping[index])\n",
        "\n",
        "            seed = np.append(seed, [[index_N]], axis=0)\n",
        "            seed = seed[1:]\n",
        "\n",
        "        melody = chords_n_notes(music)\n",
        "        melody_midi = stream.Stream(melody)\n",
        "\n",
        "    return music, melody_midi\n",
        "\n",
        "music_notes, melody = melody_generator(50, model, X_test, reverse_mapping, L_symb, temperature=1.0)\n",
        "melody.write('midi', 'drive/MyDrive/Colab Notebooks/output.mid')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PH3TRGDG_PJY"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
